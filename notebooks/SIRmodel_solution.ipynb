{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Problem 1\n",
    "* Task description / introduction to SIR model: see [this notebook](SIRmodel.ipynb)\n",
    "* We use [`odeint`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html) to solve the system of ODEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(y, t, N, c, w):\n",
    "    \"return the derivatives defining the differential equations of the SIR model, y = (S, I, R)\"\n",
    "    S, I, R = y\n",
    "    dS = -c*S/N*I\n",
    "    dI =  c*S/N*I -w*I\n",
    "    dR =           w*I\n",
    "    return dS, dI, dR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve system of ODEs\n",
    "def SolveSIRAndPlot(F, y0, ts, args):\n",
    "    # solve ODE\n",
    "    S, I, R = odeint(F, y0, ts, args).T\n",
    "    # plot result\n",
    "    plt.plot(ts, S, label = \"susceptible\")\n",
    "    plt.plot(ts, I, label = \"infected\")\n",
    "    plt.plot(ts, R, label = \"recovered\")\n",
    "    plt.xlabel(\"time [days]\")\n",
    "    plt.ylabel(\"individuals [1]\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time steps [assume days as time unit]\n",
    "def TimeSteps(t_min, t_max, dt):\n",
    "    return np.arange(t_min, t_max+dt, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions and constants\n",
    "y0 = (999, 1, 0) # (note: we use floats although individual counts are integers)\n",
    "N  = sum(y0)\n",
    "c  = 0.10\n",
    "w  = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R0 = {c/w} (basic reproduction number)\")\n",
    "if c/w > N/y0[0]: print(\"Outbreak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSteps(t_min = 0, t_max = 500, dt = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SolveSIRAndPlot(F, y0, ts, args = (N, c, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feeling for the impact of the model parameters on the time evolution, we can use [``ipywidgets``](https://ipywidgets.readthedocs.io/)  in jupyter notebooks, which allow us to add interactive sliders to change the model parameters and call a function whenever the slider has been moved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "interact(lambda c: c**2, c=(0, 0.5, 0.05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "interact(lambda c, w, t_max: \n",
    "             SolveSIRAndPlot(F, y0, TimeSteps(0, t_max, 5), \n",
    "                             args = (N, c, w)), \n",
    "         c=(0, 0.5, 0.05),\n",
    "         w=(0, 0.5, 0.05),\n",
    "         t_max=(100, 500, 100),\n",
    "         continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the number of infected individuals starts decreasing once $S < N/R_0$.\n",
    "\n",
    "This can also be derived from ${\\frac {dI}{dt}}=c{\\frac {SI}{N}}-wI = I (c \\frac SN - w)$: \n",
    "${\\frac {dI}{dt}}$ is negative iff $c \\frac SN < w \\Leftrightarrow S < \\frac{wN}c = N/R_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "This is an open-ended project task. Here, we will just look at some basics to get you started on your own investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### same code as in task\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from requests_cache import CachedSession # if you get an error, install this with: pip install requests_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = CachedSession('../data/cache_plot_corona_cases', backend='sqlite', expire_after = 86400)\n",
    "\n",
    "def SaveURL(url, path):\n",
    "  with open(path, \"w\") as outf:\n",
    "    outf.write(GetFromURL(url))\n",
    "    \n",
    "def GetFromURL(url):\n",
    "  response = session.get(url)\n",
    "  print(f\"Loaded {url} from cache: {response.from_cache}\")\n",
    "  if response.status_code != 200:\n",
    "    print(f\"Request failed with code {response.status_code}\")\n",
    "    return None\n",
    "  else:\n",
    "    return response.text\n",
    "\n",
    "def LoadDataset(url, local_path, date_column, cases_column):\n",
    "  SaveURL(url, local_path)\n",
    "  df = pd.read_csv(local_path, parse_dates = [date_column])\\\n",
    "         .set_index(date_column)\n",
    "  print(\"Last data point:\")\n",
    "  print(df.tail(1)[cases_column])\n",
    "  return df\n",
    "\n",
    "# RKI, documentation: https://github.com/robert-koch-institut/SARS-CoV-2-Nowcasting_und_-R-Schaetzung/#readme\n",
    "dfr = LoadDataset(\"https://raw.githubusercontent.com/robert-koch-institut/SARS-CoV-2-Nowcasting_und_-R-Schaetzung/main/Nowcast_R_aktuell.csv\", \n",
    "                  \"/tmp/Nowcast_R_aktuell.csv\",\n",
    "                  \"Datum\",\n",
    "                  \"PS_COVID_Faelle\")\n",
    "# JHU, documentation: https://github.com/owid/covid-19-data/tree/master/public/data#readme\n",
    "dfj = LoadDataset(\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/jhu/new_cases.csv\", \n",
    "                  \"/tmp/new_cases.csv\",\n",
    "                  \"date\",\n",
    "                  \"Germany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can work with the data.\n",
    "\n",
    "First, look at the data in tabular form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's always a good idea to plot a dataset to see whether it makes sense intuitively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Curve(df, colname, label):\n",
    "  l1 = plt.plot(df[colname], label = label)\n",
    "  # mark last point with a star\n",
    "  last = df.tail(1)\n",
    "  plt.plot(last.index, last[colname], \"*\", color = l1[0].get_color())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following two lines increase the size of the following plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 8] \n",
    "# plot RKI data\n",
    "Plot_Curve(dfr, \"PS_COVID_Faelle\", \"Nowcast\")\n",
    "# plot JHU data\n",
    "Plot_Curve(dfj, \"Germany\", \"JHU\")\n",
    "# style\n",
    "plt.tick_params(right = True, labelright = True)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"New cases / day (Germany)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "###\n",
    "plt.xlim(pd.Timestamp('2022-01')); # show from beginning of 2022\n",
    "plt.plot(df[df[\"Germany\"].isna()].fillna(0), \"*\"); # show nans (e.g. one point in 2022-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe:\n",
    "* JHU has very strong fluctuations\n",
    "* most recent days are missing in Nowcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a shorthand for the JHU numbers for Germany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfj[[\"Germany\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First issue with the data:  Sometimes the number of new cases per day are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "*It seems that the issue tackled in the following is no longer present -- maybe they have changed this, as it says, \"In rare cases where our source for confirmed cases & deaths reports a negative daily change due to a data correction, we set the corresponding metric (new_cases or new_deaths) to NA.\". (That's why we plotted the N/A above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason given in README: \n",
    "> Note: the number of cases or deaths reported by any institution—including JHU, the WHO, the ECDC and others—on a given day does not necessarily represent the actual number on that date. This is because of the long reporting chain that exists between a new case/death and its inclusion in statistics. This also means that negative values in cases and deaths can sometimes appear when a country corrects historical data, because it had previously overestimated the number of cases/deaths. Alternatively, large changes can sometimes (although rarely) be made to a country's entire time series if JHU decides (and has access to the necessary data) to correct values retrospectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # \"min\" would be negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, pandas provides a handy solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.clip(lower = 0).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum() - df.clip(lower = 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're artificially reducing the sum. But wait... that's today's number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[df[\"Germany\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems only the last value is wrong, so probably not too much a concern.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second issue with the data: Day-to-day fluctuations. Unlikely to be real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplest solution: rolling average with [`pandas.DataFrame.rolling`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html). \n",
    "Uses [`pandas.DataFrame.assign`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html) to add a column to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(rolling = df[\"Germany\"].rolling(\"7d\", center = True).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "plt.plot(df[\"Germany\"], \"b\", alpha = 0.4)\n",
    "plt.plot(df[\"rolling\"], \"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another idea: study tendency over weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) has useful attributes, e.g., the week day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(weekday = df.index.weekday)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: there is [`loc` and `iloc`](https://stackoverflow.com/a/31593712/143931) to access rows and columns in pandas `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"01.11.2020\":\"30.04.2021\"].plot.scatter(\"weekday\", \"Germany\", alpha = 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Hard to see anything here as numbers vary a lot even when selecting a subset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(avg = df[\"Germany\"] / df[\"rolling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(\"weekday\", \"avg\", alpha = 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a trend -- however, be careful with interpretation as the delay in reporting numbers is unclear. Also, we saw that the numbers for the last weeks are zero on weekends and holidays, whereas there are non-zero value in the above plot for all days, so clearly there are non-zero numbers for weekends at earlier times, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check that by selecting rows where the daily new cases are zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Germany\"] == 0][[\"Germany\", \"weekday\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it seems for most weekends we do have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}