{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and terms\n",
    "\n",
    "As we saw before, linear classifiers are often not the best at solving complicated problems. Neural networks (NNs) introduce nonlinearity. They were originally developed as mathematical models of the information processing capabilities of biological brains, and were popular in the 80s and early 90s. Recently, they have become popular again, especially as deep neural networks (DNNs), including convolutional NNs (CNN), recurrent NNs (RNN), etc. \n",
    "Those more complicated variants are beyond the scope of this course, so let's start with the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons in the brain\n",
    "* high plasticity --- whenever you memorize a number, you physically alter your body (brain)\n",
    "* nerve cells = \"neurons\", about 100 billion, lots of different types\n",
    "* chemical reactions control electrical potential inside soma (body of neuron)\n",
    "* membrane potential > threshold $\\Rightarrow$ neuron \"fires\": pulses of fixed strength and duration are sent down the axon ([all-or-none law](https://en.wikipedia.org/wiki/All-or-none_law))\n",
    "* axons provide connections (synapses) to many other neurons\n",
    "* learning modifies strength of synaptics connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram of basic neuron and components](../figures/800px-Components_of_neuron.jpg)\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/File:Components_of_neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial neuron networks\n",
    "Simplest mathematical model: McCulloch-Pitts neuron, where the activation function is simply a comparison of summed inputs to threshold.\n",
    "\n",
    "Correspondence with biological neuron:\n",
    "* weighted inputs $\\sim$ synapses (with different strengths)\n",
    "* summation (= transfer function) $\\sim$ signal collection in soma\n",
    "* activation function $\\sim$ neuron fires or not\n",
    "* activation $\\sim$ signal sent down the axon\n",
    "\n",
    "![a single neuron of an artifical network](https://upload.wikimedia.org/wikipedia/commons/6/60/ArtificialNeuronModel_english.png)\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Backpropagation#/media/File:ArtificialNeuronModel_english.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in brain, need large networks of neurons to achieve complexity needed to solve ML problems.\n",
    "\n",
    "**Perceptron** = collection of McCulloch-Pitts neurons = simplest NN. Can be proven to solve any classification problem that is linearly separable, but cannot, e.g., model a simple XOR of inputs $\\Rightarrow$ need higher complexity.\n",
    "\n",
    "Below is a diagram of a **multilayer perceptron** (MLP) with a single hidden layer:\n",
    "![NNFig](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)\n",
    "\n",
    "circles = neurons, arrows = connections (directed acyclic graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the network is **dense**; every node of the hidden layer is connected to all previous and following nodes. \n",
    "The arrows indicate that information flows from left (the input) to the right (the output). Every arrow has an assigned **weight** that is a free parameter in the training of the network. \n",
    "\n",
    "Computing a series of weighted sums as is done by the above network is mathematically the same as computing just one weighted sum. An MLP with multiple linear hidden layers that all just sum up the inputs is thus equivalent to an MLP with a single linear hidden layer. To make this model more powerful than a linear model, a nonlinear function, the **activation function**, is applied to the weighted sum for each neuron in the hidden layer and used to determine the output that is propagated as input to the following neurons.\n",
    "\n",
    "The number of neurons in the output layer and the choice of **output activation function** depend on the task the network is intended for. For **binary classification** tasks, a typical setup has a single output neuron with a logistic sigmoid activation.\n",
    "Large neural networks made up of many hidden layers of computation go under the term **deep learning**. Note that for dense layers, the number of parameters increases linearly in the number of hidden layers but quadratically in the number of neurons in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of the mathematics behind NNs\n",
    "* One can write the output from one neuron as $a_i = g\\left(\\theta_i^T x_i\\right)$, where $i$ is the index of the neuron, $x_i$ its vector of inputs, and $\\theta_i$ are the weights of the input connections of the neuron (also a vector). $g$ is the activation function. \n",
    "* The example NN in the sketch above has an input layer (layer 1), a single hidden layer (layer 2), and an output layer (layer 3). \n",
    "* Combining the outputs of all neurons from one layer into one vector $z = \\{z_i\\}_i$, we can write $z^{(j)} = \\Theta^{(j-1)}a^{(j-1)}$ with an upper index to label the layer. The matrix $\\Theta^{(j-1)}$ is formed from all weights of all neurons in layer $j-1$.\n",
    "* Then $a^{(j)} = g(z^{(j)})$. Thus evaluating the NN is a series of matrix multiplications followed by activation functions. (Which makes obvious that without the nonlinearity introduced by the activation functions, the whole NN would still be a linear map.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the NN, we have to determine the weight matrices $\\Theta^{(i)}$ (which are basically just a bookkeeping devices holding the weights of all input connections for all neurons of one layer each) that minimize the **cost function**.\n",
    "This is done using a method called **backpropagation**.\n",
    "The cost function of a NN is similar to what we have for logistic regression, modified to take into account possible multiple outputs, and with more complicated regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "To train the network, we define a cost function $E$ that is minimized by propagating \"errors\" in the output values  backwards, where the error specifies the difference between the current output of the network given some input and the correct output corresponding to this input.\n",
    "\n",
    "In general we only know the desired output at the very end of the network, i.e. for the predictions made through the output layer, and can thus only compute the error for the last layer. However, the output will depend on the weights of all layers in the network, and the idea of backpropagation is to propagate the error of the output of the last layer back and to compute the gradient of the output with respect to the weights, which then allows to adjust the weights layer by layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using notation from above: \n",
    "$$\\text{net}_j = \\sum_i w_{ij} x_i + \\theta_j$$ (interpreting \"threshold\" as the bias $\\theta_j$), $$o_j = \\varphi(\\text{net}_j),$$\n",
    "and $E = E(\\vec o)$.\n",
    "\n",
    "The partial derivatives of the cost function with respect to the weights can be obtained from the chain rule,\n",
    "$$\\frac{\\partial E}{\\partial w_{ij}} \n",
    "    = \\frac{\\partial E}{\\partial o_{j}} \\frac{\\partial o_{j}}{\\partial w_{ij}}\n",
    "    = \\frac{\\partial E}{\\partial o_j} \\frac{\\partial o_j}{\\partial\\text{net}_j} \\frac{\\partial \\text{net}_j}{\\partial w_{ij}}$$ \n",
    "and the weights are modified such that the cost function is reduced:\n",
    "$$ \\Delta w_{ij} = - \\eta \\frac{\\partial E}{\\partial w_{ij}}.$$ <!--= - \\eta \\delta_j o_i -->\n",
    "$\\eta$ is a metaparameter in the training that determines the **learning rate**.\n",
    "\n",
    "In the derivative of the cost function, the terms from right to left are\n",
    "* the output of the neuron $i$ feeding into the neuron $j$ with weight $w_{ij}$, which we see from above is $\\frac{\\partial \\text{net}_j}{\\partial w_{ij}} = x_i$\n",
    "  * for a neuron in the first hidden layer, $x_i$ is just the $i$th entry of the input vector, for the following layers it is the output of a neuron in the previous layer\n",
    "* the derivative of the activation function, $\\frac{\\partial o_j}{\\partial\\text{net}_j} = \\frac{\\partial \\varphi(\\text{net}_j)}{\\partial\\text{net}_j} = \\varphi'(\\text{net}_j)$\n",
    "* and for a neuron in the last layer, $\\frac{\\partial E}{\\partial o_j}$ is per definition the derivative of the cost function with respect to the output of this neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the quadratic difference (mean squared error) $E = (\\hat y - y)^2$ as the cost function, $\\frac{\\partial E}{\\partial o_j} = 2(\\hat y_j - y_j)$, such that for a neuron in the output layer:\n",
    "$$\\frac{\\partial E}{\\partial w_{ij}} \n",
    "    = 2(\\hat y_j - y_j) \\varphi'(\\text{net}_j) x_i$$ \n",
    "$\\Rightarrow$ we can compute the modification $\\Delta w_{ij}$ we need to do to the weight $w_{ij}$ of a neuron in the output layer.\n",
    "   \n",
    "For a neuron in any hidden layer, $\\frac{\\partial E}{\\partial w_{ij}}$ depends on the error terms of all the following layers, which is why we need to compute backwards. <!--- Here, the notation becomes impossible if we don't use an additional index for the layer -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--For more details on backpropagation, take a look, for example, at the [ML course][1] mentioned above.-->\n",
    "The backpropagation formula is explicitly written down in a clean way, e.g., in [this wiki][2].\n",
    "Another explanation of the backpropagation with lots of nice animations is given by 3Blue1Brown in the [video \"Backpropagation calculus\"][3] as part of their series on Deep learning.\n",
    "\n",
    "\n",
    "[1]: https://www.coursera.org/learn/machine-learning\n",
    "[2]: https://brilliant.org/wiki/backpropagation/\n",
    "[3]: https://www.youtube.com/watch?v=tIeHLnjs5U8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimization\n",
    "\n",
    "Although the loss function of a neural network is typically highly non-convex with many local minima, the optimization is typically performed via gradient descent. That means the parameters are updated step-by-step by following the gradient (steepest descent/ascent). The total cost function of the whole training dataset is the mean of the cost of each individual training example. This allows to perform a **stochastic gradient descent** (SGD) by calculating gradient updates only on a random subset (**batch**) of the training data. The advantages of this method are:\n",
    "\n",
    "* less computational effort for each gradient update since only a subset of examples has to be (back-)propagated through the network\n",
    "* less memory consumption\n",
    "* random fluctuations can help to escape local minima\n",
    "\n",
    "On the other hand, typically more gradient steps are needed when the gradient is calculated from smaller batches and too small batch sizes can lead to large fluctuations of the loss value during training. As a consequence, there is a trade-off between fast computation of each gradient step and the total number of gradient steps needed, which is tuned by choosing the appropriate batch size. \n",
    "There are many improvements to the plain gradient descent that try to adjust the step sizes (**learning rate**) dynamically, possibly on a per-parameter basis. One of the most popular optimization algorithm currently (2019) is [Adam](https://arxiv.org/abs/1412.6980v8). \n",
    "A nice overview can be found at http://ruder.io/optimizing-gradient-descent/index.html or https://arxiv.org/abs/1609.04747."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "The activation function of a neuron transforms the net input into the activation (output) of the neuron, i.e. whether the neutron is firing or not.\n",
    "\n",
    "* Differentiable functions allow the network to be trained with gradient descent.\n",
    "* Activation functions map the (potentially unbounded) input range of the net input of the neurons to a finite output range and are therefore sometimes referred to as squashing functions.\n",
    "* Vanishing gradient problem: e.g. for sigmoid function, gradient becomes very small for large values, leading to small learning effects (training is slowed down)\n",
    "\n",
    "Popular choices include ([source][2]):\n",
    "![1]\n",
    "\n",
    "* For example, if we use a logistic function (as special case of the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function)) as the activation function, we can have $g\\left(\\theta^Tx\\right) = \\frac{1}{1+\\mathrm{exp}\\left(-\\theta^Tx\\right)}$, \n",
    "* or if a Rectified Linear Unit (ReLU), $g\\left(\\theta^Tx\\right) = \\mathrm{max}\\left(0, \\theta^Tx\\right)$. \n",
    "\n",
    "[1]: ../figures/activation_functions.png \"overview of commonly used activation functions\"\n",
    "[2]: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn` offers [these](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) activation functions: `identity`, `logistic`, `tanh`, `relu`\n",
    "* Other frameworks like [Keras][4] provide a larger set of activation functions: \n",
    "  * shown above: `sigmoid`, `tanh`, `ReLU` (rectified linear unit)\n",
    "  * and more: `linear`, [`ELU`][3] (exponential linear unit), [`Softmax`][5], ...\n",
    "  * in addition, e.g. learnable activations (which maintain a state) are available as advanced activation layers. These include `PReLU` and `LeakyReLU`.\n",
    "\n",
    "[3]: https://arxiv.org/pdf/1511.07289.pdf\n",
    "[4]: https://keras.io/activations/\n",
    "[5]: https://de.wikipedia.org/wiki/Softmax-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}