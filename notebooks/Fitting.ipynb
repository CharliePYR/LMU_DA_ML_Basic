{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245d0ea5",
   "metadata": {},
   "source": [
    "# Fitting\n",
    "\n",
    "Taking some material from https://github.com/klieret/HEPFittingTutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de536aa7",
   "metadata": {},
   "source": [
    "## Fit a line to data by minimizing the squared distance\n",
    "\n",
    "The basic idea of fitting consists of minimizing a cost function by adjusting parameters of some function template.\n",
    "\n",
    "Let's define some random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caaec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.linspace(-1, 1, 10)\n",
    "y_data = -1 + 3 * x_data + 2 * np.random.random_sample(len(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f870ba",
   "metadata": {},
   "source": [
    "And take a quick look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_data, 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598e526",
   "metadata": {},
   "source": [
    "This looks like a line, so this is what we want to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ae144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, params):\n",
    "    a, b = params\n",
    "    return a * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af6d10",
   "metadata": {},
   "source": [
    "The line is defined as $f(\\vec x) = a \\vec x + b$ and maps a vector of x coordinates to y coordinates.\n",
    "The two parameters a and b are collected in vector ``params``.\n",
    "\n",
    "Now the idea is to minimize the distance of our function ``line`` to the y coordinates of the data, so we define\n",
    "another function ``chi2``, which, for every set of parameters returns the sum of the squared distances of data points to function values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(params):\n",
    "    return np.sum(np.square(y_data - line(x_data, params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce8fe08",
   "metadata": {},
   "source": [
    "Let's look at this step by step: \n",
    "\n",
    "* ``line(x_data, params)``: Here we passed on the parameters of ``chi2`` to the line function which we evaluate for all the data x values. The result is a vector y values.\n",
    "* ``y_data - line(x_data, params)``: This is then the vector of distances between the data y values and the y values of our function\n",
    "* ``np.square(y_data - line(x_data, params))``: The vector of squared distances\n",
    "* ``np.sum(np.square(y_data - line(x_data, params)))``: Summing everything up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef573d9b",
   "metadata": {},
   "source": [
    "First, try to manually tune the parameters and see how `chi2` changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [3, 0.1]\n",
    "plt.plot(x_data, y_data, 'ko', label=\"data\")\n",
    "plt.plot(x_data, line(x_data, params), label=\"line\")\n",
    "plt.legend()\n",
    "print(\"Chi2: \", chi2(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24991438",
   "metadata": {},
   "source": [
    "Of course we don't do this manually in practice - especially with higher number of parameters this can be challenging.\n",
    "\n",
    "Scipy provides [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html). It needs start points, which we just set to ``(0, 1)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ffabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(chi2, (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1054a5",
   "metadata": {},
   "source": [
    "Note how ``minimize`` is a higher order function, that takes a function as first argument!\n",
    "\n",
    "The results object contains quite a lot of useful information, but we just want the values of our parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e8dea",
   "metadata": {},
   "source": [
    "The value of `chi2` for the parameters that minimize it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabe090",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27914ab2",
   "metadata": {},
   "source": [
    "Let's plot to see how well it fits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting our data point\n",
    "plt.plot(x_data, y_data, 'ko', label=\"data\")\n",
    "plt.plot(x_data, line(x_data, result.x), label=\"fit\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba3bf4",
   "metadata": {},
   "source": [
    "What we just did is called a \"Least Square Fit\"\n",
    "\n",
    "Fitting an arbitrary (non-linear) Function to  weighted points (= measurements with uncertainties).\n",
    "\n",
    "**Basic principle:**  \n",
    "Minimize $\\chi^2$, the quadratic difference between measurement points and fit, weighted by inverse uncertainty squared:\n",
    "\n",
    "$$ \\chi^2 = \\sum \\frac{(y_{meas}-y_{fit})^2}{  ( \\Delta y )^2} $$\n",
    "\n",
    "The resulting value for $\\chi^2$ is an important check whether the fitting model is sensible:\n",
    "\n",
    "$$ \\left< \\frac{\\chi^2}{  (n_{points} - n_{par} )} \\right> \\approx 1$$\n",
    "\n",
    "$n_{points} - n_{par}$ is the number of degrees of freedom (ndf) in our optimization problem.\n",
    "\n",
    "**Note** In our example with the line we didn't divide by the uncertainty in the definition of `chi2`, so we made the implicit assumption that all data points are equally weighted. Not knowing the uncertainty of the data points also means we can't use $\\chi^2$ to test goodness of fit by comparing it to the number of degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e8309",
   "metadata": {},
   "source": [
    "## Using `scipy.optimize.curve_fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcd254",
   "metadata": {},
   "source": [
    "For a least-square-fit we don't need to write the cost function manually, but can instead use `scipy.optimize.curve_fit`.\n",
    "\n",
    "For curve fit we don't need to put all parameters into one tuple. Instead the first argument of the fit function is interpreted to be the input data, and all remaining arguments the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b33ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, b):\n",
    "    return line(x, [a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc34e8",
   "metadata": {},
   "source": [
    "`curve_fit` will return the fitted parameters and their covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit, pcov = curve_fit(f, x_data, y_data, p0=(1, 0))\n",
    "pfit, pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166c2f8",
   "metadata": {},
   "source": [
    "### Fit uncertainties and covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfd483",
   "metadata": {},
   "source": [
    "The covariance matrix shows the variances on the fit parameters on the diagonal and their covariances on the off diagonal elements.\n",
    "\n",
    "**Note:** Since we did not provide uncertainties on the data points (would be done using the `sigma` argument to `curve_fit`) the overall normalization of $\\chi^2$ is undetermined. By default, `curve_fit` multiplies the covariance matrix by $\\chi^2_\\mathrm{min}/\\mathrm{ndf}$ which effectively scales the uncertainties on the data points to match the observed residuals after the fit. This can be turned off by using `absolute_sigma=True` which can be used when uncertainties are provided.\n",
    "\n",
    "So the one standard deviation errors on the fit parameters will be given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f699c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = pfit\n",
    "a_err, b_err = np.sqrt(np.diag(pcov))\n",
    "print(\"a = {:.2f} +/- {:.2f}\".format(a, a_err))\n",
    "print(\"b = {:.2f} +/- {:.2f}\".format(b, b_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828a4a5",
   "metadata": {},
   "source": [
    "The covariances indicate how much the parameters are correlated, that is how much greater values of one parameter correspond to greater values of the other one.\n",
    "\n",
    "You can try this out. Change on of the parameters slightly and see if there is a way to get a better `chi2` again by changing the other one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d864e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test = a + 1\n",
    "(b_test,), _ = curve_fit(lambda x, b: f(x, a + 1, b), x_data, y_data, p0=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test, b_test = [a + 1, b]\n",
    "plt.plot(x_data, y_data, \"ko\")\n",
    "yfit = f(x_data, a_test, b_test)\n",
    "plt.plot(x_data, yfit)\n",
    "print(\"Chi2:\", ((yfit - y_data) ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f733a8",
   "metadata": {},
   "source": [
    "Also, if we fix a to a value slightly away from the optimum, and fit `b` again, the optimal `b` won't change significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit(lambda x, b: f(x, a + 1, b), x_data, y_data, p0=(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e655705",
   "metadata": {},
   "source": [
    "In this case, we have the same number of points on the positive and negative x-axis, so a higher slope (parameter `a`) puts the data points on the positive x-axis below the fitted line and on the negative x-axis above the fitted line.\n",
    "\n",
    "Changing the parameter `b` will cause an overall shift to the top or bottom, so there is no way to compensate a less optimal value of `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e4a6b",
   "metadata": {},
   "source": [
    "The situation changes if we only look at data points on the positive x-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd501ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2 = np.linspace(0, 1, 10)\n",
    "y_data2 = -1 + 3 * x_data2 + np.random.random_sample(len(x_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b828889",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data2, y_data2, \"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57228947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit2, pcov2 = curve_fit(f, x_data2, y_data2, p0=(1, 0))\n",
    "pfit2, pcov2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff1797",
   "metadata": {},
   "source": [
    "Here, the off diagonal elements have a significant (negative) non-zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2, b2 = pfit2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753c41f",
   "metadata": {},
   "source": [
    "Now we can compensate a slightly higher value of `a` by a slightly lower value of `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_test, b2_test = [a2 + 1, b2]\n",
    "plt.plot(x_data2, y_data2, \"ko\")\n",
    "yfit = f(x_data2, a2_test, b2_test)\n",
    "plt.plot(x_data2, yfit)\n",
    "print(\"Chi2:\", ((yfit - y_data2) ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit(lambda x, b: f(x, a2 + 1, b), x_data2, y_data2, p0=(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccae922",
   "metadata": {},
   "source": [
    "Since we know the \"real\" distribution of our data points (we generated them after all) we can check with toy experiments how well the estimation of uncertainties and covariances from the fit worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97177eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_toy():\n",
    "    x_data = np.linspace(0, 1, 10)\n",
    "    y_data = -1 + 3 * x_data + np.random.random_sample(len(x_data))\n",
    "    pfit, pcov = curve_fit(f, x_data, y_data, p0=(1, 0))\n",
    "    return pfit, pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_params = np.array([fit_toy()[0] for i in range(1000)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*toy_params, marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(toy_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7828b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcov2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d35f48",
   "metadata": {},
   "source": [
    "Which looks pretty similar! Note, however, these intervals are typically interpreted as confidence intervals, so what we would actually be interested in is, do 68.27% of all intervals (in repeated experiments that assume different true values) contain the true value ([coverage probability](https://en.wikipedia.org/wiki/Coverage_probability))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88063d6",
   "metadata": {},
   "source": [
    "### Error propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04e70d",
   "metadata": {},
   "source": [
    "One thing we can do with this covariance matrix is to visualize uncertainties on the fit using [linear error propagation](https://en.wikipedia.org/wiki/Propagation_of_uncertainty). In this case we can simply calculate it manually:\n",
    "\n",
    "$$\\sigma_y ^ 2 = \\left(\\frac{\\partial y}{\\partial a} \\sigma_a \\right)^2 + \\left(\\frac{\\partial y}{\\partial b} \\sigma_b \\right)^2 + 2\\frac{\\partial y}{\\partial a}\\frac{\\partial y}{\\partial b}\\sigma_{ab}$$\n",
    "\n",
    "where $\\sigma_a, \\sigma_b$ are the variances and $\\sigma_{ab}$ is the covariance. With $y = ax + b$ this becomes:\n",
    "\n",
    "$$\\sigma_y ^ 2 = (x\\sigma_a)^2 + \\sigma_b^2 + 2x\\sigma_{ab}$$\n",
    "\n",
    "where we can take $\\sigma_a, \\sigma_b, \\sigma_{ab}$ from the covariance matrix:\n",
    "\n",
    "$$\n",
    "\\pmatrix{\n",
    "    \\sigma_a^2 & \\sigma_{ab} \\\\\n",
    "    \\sigma_{ba} & \\sigma_b^2\n",
    "}\n",
    "$$\n",
    "\n",
    "Let's visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92861632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_y = np.sqrt((x_data2 * np.sqrt(pcov2[0, 0])) ** 2 + pcov2[1, 1] + 2 * x_data2 * pcov2[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = line(x_data2, pfit2)\n",
    "plt.fill_between(x_data2, y - sigma_y, y + sigma_y, alpha=0.5)\n",
    "plt.plot(x_data2, y)\n",
    "plt.plot(x_data2, y_data2, \"ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100ceea",
   "metadata": {},
   "source": [
    "For more generic templates/functions you can do that automatically. Either use the [uncertainties](https://pythonhosted.org/uncertainties) package (for functions described by simple formulas) or calculate it numerically by varying each parameter up and down and using half of the resulting interval as a replacement for $\\frac{\\partial f}{\\partial x_i}\\sigma_{x_i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71363614",
   "metadata": {},
   "source": [
    "### Goodness of fit\n",
    "\n",
    "Taking some inspiration from http://www.pp.rhul.ac.uk/~cowan/stat_course.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3aca8c",
   "metadata": {},
   "source": [
    "Let's have a look at these data points (this time with uncertainties):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76316857",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
    "y_data = np.array([2.7, 3.9, 5.5, 5.8, 6.5, 6.3, 6.7, 6.2, 6.0])\n",
    "yerr_data = np.array([0.3, 0.5, 0.7, 0.6, 0.4, 0.3, 0.7, 0.8, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d318c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x_data, y_data, yerr=yerr_data, fmt=\"ko\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d89085",
   "metadata": {},
   "source": [
    "And fit a line again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_linear(x, a, b):\n",
    "    return a * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1367a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit, pcov = curve_fit(f_linear, x_data, y_data, sigma=yerr_data, absolute_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x_data, y_data, yerr=yerr_data, fmt=\"ko\")\n",
    "plt.plot(x_data, f_linear(x_data, *pfit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86675e46",
   "metadata": {},
   "source": [
    "That doesn't look very great. How can we quantify the quality of this fit? We look at our $\\chi^2$ statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_chi2(f, params, x, y, yerr):\n",
    "    return (((f(x, *params) - y) / yerr) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_chi2(f_linear, pfit, x_data, y_data, yerr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e495a46b",
   "metadata": {},
   "source": [
    "Reminder: As a rule of thumb, the number of degrees of freedom (number of data points - number of parameters) should be roughly equal to the $\\chi^2$ statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d75ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_data) - len(pfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc292585",
   "metadata": {},
   "source": [
    "So this rule of thumb already indicates this is not a very nice fit. We can be even more quantitative. This rule comes from the fact that the $\\chi^2$ statistic actually follows a [Chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) (which has ndf as expectation value) if we assume the data points follow a normal distribution. Using this we can calculate a p-value that answers the question \"how often would we get such a high value of $\\chi^2$ in repeated experiments, given that our function describes the data\".\n",
    "\n",
    "Scipy provides functions for common probability density functions among which there is also the chi-squared distribution. What we want to calculate is\n",
    "\n",
    "$$p = \\int\\limits_{\\chi^2_\\mathrm{min}}^{\\infty}f(\\chi^2, \\mathrm{ndf})\\mathrm{d}\\chi^2 = 1 - F(\\chi^2_\\mathrm{min}, \\mathrm{ndf})$$\n",
    "\n",
    "where $F(\\chi^2_\\mathrm{min}, \\mathrm{ndf})$ is the cumulative distribution function of a chi-squared distribution which we can calculate using `scipy.stats.chi2.cdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_pvalue(chi2, ndf):\n",
    "    return 1 - scipy.stats.chi2.cdf(chi2, ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eab013",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_pvalue(\n",
    "    f_chi2(f_linear, pfit, x_data, y_data, yerr_data),\n",
    "    len(x_data) - len(pfit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b9b55",
   "metadata": {},
   "source": [
    "which is rather low, again indicating a bad fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e4089",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Exercise</b> Fit a quadratic function to the data. What is $\\chi^2 / \\mathrm{ndf}$ now? What is the p-value?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}